**3.2.	INSTRUCTION CONTROL UNIT (ICU)**
The ICU Fetches, Decodes, and Dispatches instructions to the various Execution Units (EUs). It also handles Branches, Interrupts, Conditional Instructions. It has a simple and fast design. It executes instructions in the order that they are received from the Instruction Cache, as defined by the Instruction Pointer.
Conditional Instructions and Branches use an array of Condition Bits (CBs) which are set by Compare, Test or Logical instructions in the various EUs. The CBs can be set simultaneously by different instructions running in parallel. The ICU is responsible for synchronizing the setting and testing of CBs so that no bit is tested before it is set. Conditional Instructions are dispatched if a tested CB is true and skipped if the CB is false. Branches test for a CB to be true or false, or for the value of an Integer Register to be zero or not zero.


3.3.	LOAD-STORE UNIT (LSU)
Scalar and Vector Caches
The LSU moves data between main memory and the internal registers. The most recently used data is held in one of two high speed data caches. The Scalar Data Cache holds variable length data items which are from 8 to 128 bits in length, and which are accessed randomly. The Vector Data Cache holds fixed length data items which are always 128 bits long, and which are usually accessed sequentially. The caches are usually manged automatically by the hardware, but software can also prefetch and flush the caches. The Wikipedia article CPU Cache gives a good description of how various caches work. Because of the randomness of the Scalar Cache, it would be best to design it as “set associative”. The Vector Cache, on the other hand, would be a good candidate for a “direct mapped” cache, because the data addresses are predictable and rarely conflict. 
Internal Registers
The internal registers include: Control Registers (CR), Integer Registers (IR), Scalar Registers (SR), Type-Status Registers (TSR), and Vector Registers (VR). Scalar registers can contain integer or floating-point data. Load instructions transfer data from memory to the various registers. Store instructions transfer data from the registers to memory. Load instructions convert data from the format in memory into the format that the internal registers require. Store instructions convert data from the format in the register to that in memory. This will be explained further when we examine the various processing units in more detail.
Typed Pointers
There are two different kinds of Load and Store instructions. In the first kind the data address, and the data type are specified by fields in the instruction. In the second kind, the address and data type are specified by fields in Typed Pointers.  A typed pointer contains the data type and other control information in the upper 16 bits, and the data address in the lower 48 bits, of a 64-bit pointer register. The data address is calculated by adding the address in a typed pointer register to that of an index register. The data type specified by the type field in the pointer register also provides information on the length of the data and how the data is to be converted as it is moved between memory and the registers. Typed pointers are very flexible and powerful especially when used with vector data. They closely match the concept of reference variables in C++.
Saving Registers for Context Switching
RISC++ defines many internal registers which are needed to ensure high speed execution of individual threads. This means that many registers need to be saved and restored when the processor switches threads (context switching). In RISC++ 1.0 this problem was addressed by defining a Register Save Engine (RSE). The RSE would continually scan the various register banks and save modified registers into an area of the Scalar Data Cache specified by a Register Save Pointer (RSP). RISC++ 3.0 this function is delegated to software. This ensures that only those registers which are critical to operating thread are saved and restored.
The Save Modified IPU (SMI) instruction saves any Integer or Control registers that have been modified since the last save. Only local registers need to be saved because global registers are used by all threads. The software will issue an SMI at various checkpoints. Then when a thread switch takes place, only the most recently modified registers need to be saved by the hardware. The Restore Saved IPU (RSI) instruction is issued after control is returned to the original thread. The Scalar Registers are also saved and restored with the Save Modified Scalar (SMS) and Restore Saved Scalar (RSS) instructions. The LSU does not have any registers of its own to save but uses registers from the IPU. The VPU generally runs with interrupts disabled until the results of intermediate calculations are stored to memory.
Memory Management and Security
When parallel processing systems share memory, it creates problems with both performance and security. One way to combat these problems is to use hardware features to facilitate Process Isolation. When processes, (or threads as defined by RISC++), are isolated from one another, they are not able to share memory. All  Inter-process Communication is performed through software interrupts and implemented in the Operating System. Process Isolation also makes cache management hardware faster and less complex because it does not need to support inefficient schemes of maintaining Cache Coherence. 
The X86 has evolved from a time CPUs when memory was smaller and more expensive than it is today. As a result, the way the architecture implements Virtual Memory is complex and cumbersome. Now that real memory is larger and cheaper, and as security has become a more complex problem, a new Virtual Memory system needs to be defined. RISC++ has left Virtual Memory undefined for now. Perhaps some collaborative thinking could produce a new definition based on large amounts of real memory and modern security issues.


3.4.	INTEGER PROCESSING UNIT (IPU)
RISC++ defines 32 Integer Registers (IR), and 16 Control Registers (CR), each 64 bits wide. There are also 32 x 16-bit integer registers and 32 x 16-bit control registers. These registers are modified by the IPU and used by other Execution Units. When a CR is modified, all previously dispatched instructions must first complete. Then new instructions are controlled by the new value in the CR. It is very important that any modification of a CR be synchronized with the instructions that use it. Therefore, the following steps must be taken:
1.	Copy the Control Register to an Integer Register.
2.	Modify appropriate bits in the Integer Register.
3.	Update the Control Register:
a.	Complete the execution of previously dispatched instructions.
b.	Stall instruction fetch and decode operations in current thread.
c.	Write the new value from the IR to the CR.
4.	Continue instruction fetch, decode and dispatch.
The IPU is used primarily for simple arithmetic and logical instructions such as Add, Subtract, AND, OR, XOR, Shift Left/Right, etc. The IPU does not support multi-cycle instructions like Multiply and Divide. If the program needs to perform Multiply and Divide on integer data, it needs to use the Scalar Processing Unit (SPU). IPU Add and Subtract instructions assume 16-bit signed or 64-bit signed data. The data types in memory can be 8, 16, 32, or 64-bit integer; signed and unsigned. Data is converted between memory and register format during Loads and Stores. The IPU is used for loop counters, address arithmetic, logical operations, bit manipulation, and so forth.
The IPU exchanges data between the Integer Registers and registers in all the other EUs. This may cause stalls especially when the IPU is waiting for a register from the SPU. These stalls are considered acceptable for overall system performance. However, to avoid stalls in the IPU, the compiler should separate the tasks performed by the IPU and SPU. There is a trade-off between the goal of having a fast instruction cycle for serial instructions, and the goal of producing high Instruction Level Processing using Out of Order Execution. However, if the IPU is used for things like loop control and pointer manipulation, and the SPU is used for other calculations, then the parallelism between and within the two EUs can be optimized. 

3.5.	SCALAR DATA PROCESSING UNIT (SPU)
The SPU implements Out-of-Order-Execution using an internal Dataflow Architecture. The main features are:
1.	Support for Instruction Level Parallelism (ILP), giving faster single thread performance.
2.	Internal Data Flow Architecture. Instructions are executed as input registers become available.
3.	Data Types are specified by data in registers and not by instruction operation codes.
4.	64x64-bit Scalar Registers: 32 random access and 32 queued access.
5.	64x8-bit Type/Status Registers (TSRs). Used to support generic type instructions.
6.	TSRs also control instruction execution and error flagging.
The unit supports Instruction Level Processing by using an internal Data Flow Architecture. Instructions are placed in reservation stations to be dispatched when all the input registers are available. Thus, the instructions may execute out of the order as defined by the instruction stream. Each register has an associated 8-bit Type/Status Register which tells the execution unit the data type of each input register, and the status of the operation that produced it.

+++++++++++++++++++++++++++++++++++++++++++

4.	WHY DO WE NEED ANOTHER ARCHITECTURE?
4.1.	RISC++ COEXISTS WITH THE X86 ARCHITECTURE
The decision to introduce a new architecture should never be taken lightly. Many well designed and well-financed processors have failed in the marketplace. Meanwhile, legacy architectures like the X86 continue to dominate. The reason is simple. Software development is costly. Hardware that can run legacy software without recompilation will always be very popular especially in the PC market. The PC market has no need to move away from the dominance of Microsoft Windows and/or the X86 Architecture. For this reason, RISC++ is designed to coexist as a scientific co-processor, rather than replace X86. 
The RISC++ chip is designed to enhance scientific programming in a variety of environments:
1.	As a coprocessor on the same motherboard as an X86 chip.
2.	As a computer “stick” where the processor is mounted on a USB device.
3.	As a processor mounted on a PCI card with dedicated memory.
4.	As a computer “blade” mounted in a supercomputer system.
5.	As a Physics coprocessor in a high-performance gaming machine.
RISC++ may also be used in standalone applications that do not require X86 compatibilities, such as Linux, or other Operating System environments. The RISC++ chip does not have an integrated graphics processor as many modern X86 chips have. Therefore, if high-resolution graphics are required the system may need a dedicated graphics processor. The space that is often devoted to high-speed graphics on modern X86 chips is devoted to scientific vector processing on a RISC++ chip. 
4.2.	RISC++ IS SIMPLER THAN X86
In this document, the term “X86” includes the architecture that is implemented on many families of software compatible chips designed by Intel, AMD, and other companies. It includes both 32 and 64-bit scalar instruction sets and many variants of vector (SIMD) instruction-sets. It also includes a complex variety of options to handle real and virtual memory addressing. X86 includes: IA-32, X86-64, 3DNow!, MMX, SSE, SSE2, SSE3, SSSE3, SSE4, SSE5. Reading over those articles will show how complex and fragmented X86 has become. Each instruction set is complex on its own, but the confusing mix of which instruction sets are supported by which chip family makes the job of compilers generating portable binary code even more difficult.
Over time, the scalar instructions of X86 have evolved from 8 to 64-bit computers with considerable duplication of function, and an inadequate number of registers available to the programmer. New innovations and higher clock speeds continue to squeeze more and more performance out of the chips. Deep pipelines, Out of Order Execution, replication of resources, and other techniques all work together to produce higher and higher performance of an aging architecture based on a serial instruction stream. However, this has not come without a cost. A significant amount of resources are dedicated to supporting the complex instruction set, rather than being devoted to speed and functionality. The RISC++ architecture seeks to define a simple, yet complete instruction set that incorporates various features of “X86” which are needed for scientific processing.
4.3.	IMPORTANCE OF HIGH PERFORMANCE OF SERIAL PROCESSING
One of the ways to speed up scientific computation is by using many processors, working in parallel, each working on a part of the problem. The kinds of problems that are best served by a large degree of data parallelism are called “embarrassingly parallel” problems. Usually, this involves large data arrays which are divided up among many processors all running the same program. However, most real-world problems have sections of code that must be computed in serial.  According to Amdahl's Law,  “the speedup of a program using multiple processors in parallel computing is limited by the time needed for the sequential fraction of the program.”  
While optimizing the parallel portion of a program through parallel processors is profitable, any acceleration of the sequential portions of code does even more to the speed up the overall program. The following link compares the effect of speeding up a parallel portion of the program by a factor of 5, as opposed to speeding up the sequential portion of a program by a factor of 2: Optimizing Different Parts. As you can see, the benefits of speeding up serial code are greater for increasing overall performance than only working to improve the performance of the parallel code.
4.4.	INSTRUCTION AND DATA PARALLELISM
To provide the best computation speeds possible for the sections of code that must be run in serial, we must find individual instructions that can be run in parallel. This is called Instruction Level Parallelism (ILP).  ILP allows for the acceleration of a single thread of computation and takes place on a single processor. This is not the same as Data Level Parallelism (DLP) in which a large data set is divided up and the computation is spread over many processors.  The amount of ILP in any given application is determined by the algorithm. We will explore algorithms that have differing amounts of ILP later. The key concept needed to understand ILP is Data Dependency.  In short, if a calculation needs the result of a previous calculation, the instruction will not be dispatched until all its data items are available. In the meantime, other instructions which have received all the necessary data items will continue to be dispatched. For example:
Consider the following program:

e = a + b     
f = c + d      
m = e * f

Operation 3 depends on the results of operations 1 and 2, so it cannot be calculated until both are completed. However, operations 1 and 2 do not depend on any other operation, so they can be calculated simultaneously. If we assume that each operation can be completed in one unit of time then these three instructions can be completed in a total of two units of time, giving an ILP of 3/2.

Source – Wikipedia: Instruction Level Parallelism (ILP).
There are several ways to exploit ILP and speed up serial code which we will examine below. RISC++ is a hybrid system that uses a combination of techniques used by other theoretical and actual processors. RISC++ is designed to produce fast serial code with a simple instruction set that occupies a small foot print in memory. The architecture defines two processor types; one for scalar instructions and data and the other for processing large vectors. The scalar part is optimized for ILP and the vector part is optimized for DLP.


++++++++++++++++++++++++++




5.	VARIOUS METHODOLOGIES FOR HIGH-SPEED SERIAL PROCESSING
5.1.	DATA FLOW ARCHITECTURE
There has been much research for increasing ILP using Dataflow Architecture. This family of designs has had a variety of proposed implementations, implemented in both hardware and software. The basic concept is to execute instructions in the order that data arrives at the input to the instruction rather than in the order specified by an Instruction Pointer. While I am not aware of any general-purpose computers using a strict data flow design at the ISA level, the concepts have been used in a variety of applications. (See above link). In some sense, all the methodologies for increasing ILP discussed below are built on the foundation of research done in Dataflow Programming.
5.2.	OUT OF ORDER EXECUTION (OOOE)
The most common way to speed up a serial instruction stream is called Out of Order Execution (OOOE). This method starts with a traditional Von Neumann Architecture which uses an instruction pointer and branch instructions to define the sequence of instructions. Then as serial instructions are decoded they are placed in Reservation Stations where they wait until all their input data are ready. As the input data (source registers) become available, the instructions are sent to the appropriate parallel execution units (adders, multipliers, logical units, etc.) for execution. The instructions are often executed in a different order than the program sequence in memory. However, the results are written back to the registers in the original program order. OOOE is used by most modern implementations of X86. It is also used in the IBM PowerPC and various other processors. The main advantage of OOOE is that it preserves legacy binary code while still improving single thread performance. The main disadvantages are that it requires highly complex hardware and that only a small window of binary code is optimized at a time.
5.3.	VERY LONG INSTRUCTION WORD (VLIW)
The complexities and disadvantages of OOOE led Intel to invest a considerable amount of time and money in an ISA called IA-64 also known as Itanium. This processor family was designed to solve the problems created by the complex hardware needed to support X86 and OOOE. The job of reordering instructions to support ILP was moved from the hardware to the Compiler. Highly sophisticated compilers would examine the entire program’s source code and determine which instructions could be executed in parallel. Then the parallel instructions would be grouped together in a Very Long Instruction Word (VLIW). The IA-64 defined a 128-bit bundle of 3 instructions which were 41 bits each. The remaining 5 bits were used for routing instructions to various execution units. The 128-bit bundles could be linked together to create as many parallel instructions as the hardware could support but the maximum number of instructions that were dispatched per cycle was typically six.
Itanium had two major disadvantages that made it less of a marketing success than Intel had hoped. The first was that customers were reluctant to move away from the X86 with its huge inventory of compatible software. The second was that developing complex new compilers was very expensive. Still, while the Itanium never replaced X86 in popularity, it filled a niche market where it performed quite well.
5.4.	MAJC BY SUN MICROSYSTEMS
Another less well-known VLIW based Architecture was called MAJC (Microprocessor Architecture for Java Computing). This processor designed by Sun Microsystems was an attempt to leverage the fact that the JAVA Programming Language used a technique called Just in Time Compilation (JIT) to dynamically convert Java Bytecode into machine language. MAJC utilized a variable length VLIW instruction which was 1 to 4 instructions long. Each instruction was a fixed length of 32 bits. MAJC also used a single set of registers for integer and floating-point operations. This simplified the dispatching hardware and allowed for up to four floating-point or four integer instructions per cycle or any combination of the two. MAJC was only used internally at Sun, but the idea of using JIT to compile directly to a VLIW machine code was later used to emulate X86 as described below.
5.5.	TRANSMETA AND CODE MORPHING
Just as Sun and the MAJC used JIT compilation to convert Java Byte Code into a VLIW based machine language, a company called Transmeta used Code Morphing Software to translate X86 byte code into a proprietary VLIW.  One of the advantages of Code Morphing was that new features of X86 could be added to the supported architecture features without changing the hardware. The simpler hardware also cost less, consumed less power and produced less heat. Larger blocks of binary code could be analyzed for translation than when decoding was done by hardware. But doing translation in software rather than hardware did affect the performance of Transmeta chips. As time went on, the advantages of lower cost, speed, power, and heat were overcome by advances in newer X86 chips designed by Intel and AMD. For a full history of Transmeta with its technology and finances see the Transmeta link referenced above.
5.6.	QUEUED OPERANDS
Another less known methodology for supporting ILP and speeding up serial code is using queued operands. In this methodology, register dependencies are eliminated by having instructions read input operands from the head of a Queue and write the results to the tail. This eliminates certain Data Hazards which prevent instructions to be executed in parallel. Examples of operand queues in RISC++ will be presented later in this document.
To my knowledge, no hardware has been manufactured and marketed where the programmer’s view of the hardware is an ISA based on queued operands. But queued operands are used both in software compilers and in proprietary OOOE hardware. The following links contain excellent resources for the study of increasing ILP through queued operands: 
•	Operand queues for streaming data: A processor register file extension (US Patent 6782470)
•	Parallel Queue Processor Architecture Based on Produced Order Computation Model (Published in: The Journal of Supercomputing Volume 32 Issue 3, June 2005)
•	Queue Machines: Hardware Compilation in Hardware (PDF)
•	Data Flow on a Queue Machine (PDF) 
•	The QC-2 Parallel Queue Processor (PDF)
6.	RISC++ FEATURE SUMMARY
RISC++ builds on the author’s research of a variety of online and print sources to provide a unique solution to the problem of the fast execution of a serial instruction stream. The following features of RISC++ facilitate high ILP with a simplified hardware design. These will be explained in more depth later in the document.
1.	The Scalar Processing Unit supports high ILP with scalar data randomly scattered in memory.
2.	The Vector Processing Unit supports high data parallelism with up to 512 bits of results per cycle.
3.	Out of Order Execution improves ILP by eliminating pipeline stalls as instructions wait for data.
4.	The Instruction Cache manages streams of fixed length instructions.
5.	The Scalar Data Cache manages random data with a variable length from 8 to 64 bits.
6.	The Vector Data Cache manages streams of parallel data which are 128, 256 or 512 bits wide.
7.	Virtual Registers facilitate the elimination of data dependencies to support high ILP.
8.	Each Virtual Register is mapped to a specific memory location in the Register Save Area (RSA). 
9.	The Register Save Engine (RSE) continually saves modified registers to speed up thread switching.
10.	RISC++ uses Typed Registers to specify data types such as Integer and Floating point.
11.	The Data Types, for each typed register, are specified in 8-bit Type/Status Registers (TSRs).
12.	The numbers and sizes of the Virtual Registers are:
a.	16 x 64-bit Control Registers, control the operation of a single thread.
b.	64 x 64-bit Fast Integer Registers, operate in a single instruction cycle.
c.	64 x 64-bit Random Access Typed Scalar Registers.
d.	64 x 64-bit Queued Access Typed Scalar Registers.
e.	128 x 64-bit Stacked Access Typed Scalar Registers.
f.	64 x 128-bit Queued Access Typed Vector Registers.
13.	Virtual Registers are renamed to Physical Registers during instruction execution.
14.	Multiple parallel Execution Units (EUs) facilitate high Instruction Level Processing (ILP).
15.	The types of Execution units are:
a.	Instruction Control Unit: Fetches, Decodes and Dispatches instructions.
b.	Load/Store Unit: Moves data between memory and various register banks.
c.	Fast Integer Unit: Single cycle Integer instructions.
d.	Scalar Multiply/Add Unit: Multiply, Add/Subtract and Logical. Typed Scalar data.
e.	Scalar Special Operations Unit: Divide, Square Root and trigonometric. Typed Scalar Data.
f.	Vector Multiply/Add Unit: Multiply, Add/Subtract, Logical. Typed Vector data. 
g.	Vector Special Operations Unit: Divide, Square Root and trigonometric. Typed Scalar Data.
16.	Multiport Register Banks allow parallel reading and writing of registers by parallel EUs.
17.	Hardware designers can optimize:
a.	The number of physical Fast Integer, Typed Scalar and Typed Vector Registers.
b.	The number of read and write ports for various physical register banks.
c.	The number of various kinds of Execution Units.
18.	Conditional Instructions streamline control logic and reduce the number of branches.
19.	Queued Operand Instructions also reduce data dependencies and reduce binary code size.
20.	Simultaneous Multithreading uses EUs more efficiently. Also, read this PDF. 
7.	OVERVIEW OF THE RISC++ ARCHITECTURE
7.1.	MAJOR PROCESSOR COMPONENTS
The following figure illustrates the major processor components in the RISC++ “Core”. We will examine the inner workings of these components in more detail later. There is a Single Memory Image for all cores. Each core processes both scalar and vector instructions and data. The Instruction Cache feeds instructions to the Instruction Control Unit (ICU). The ICU Fetches, Decodes, and Dispatches instructions to the various Execution Units (EUs). The ICU also handles Branches, Interrupts, Conditional Instructions. 
The Load/Store Unit is responsible to move data between the Scalar Data Cache, the Vector Data Cache and the corresponding Register Banks. Then, as the various EUs process individual instructions, they read the up to three input registers and write the single result back to the appropriate register bank. Inside the high-level EUs, there are several smaller EUs. These are Scalar Multiply/Add Units, Scalar Special Operation Units, Vector Multiply/Add Units, Vector Special Operation Units, and Fast Integer Units. The exact number of each kind of EU, and therefore the number of total Read and Write ports, is optimized by the hardware designers.


++++++++++++++++++++++++++


7.1.	MAJOR PROCESSOR COMPONENTS
The following figure illustrates the major processor components in the RISC++ “Core”. We will examine the inner workings of these components in more detail later. There is a Single Memory Image for all cores. Each core processes both scalar and vector instructions and data. The Instruction Cache feeds instructions to the Instruction Control Unit (ICU). The ICU Fetches, Decodes, and Dispatches instructions to the various Execution Units (EUs). The ICU also handles Branches, Interrupts, Conditional Instructions. 
The Load/Store Unit is responsible to move data between the Scalar Data Cache, the Vector Data Cache and the corresponding Register Banks. Then, as the various EUs process individual instructions, they read the up to three input registers and write the single result back to the appropriate register bank. Inside the high-level EUs, there are several smaller EUs. These are Scalar Multiply/Add Units, Scalar Special Operation Units, Vector Multiply/Add Units, Vector Special Operation Units, and Fast Integer Units. The exact number of each kind of EU, and therefore the number of total Read and Write ports, is optimized by the hardware designers.

7.2.	RISC++ CORES, THREADS AND VECTOR PROCESSOR
The RISC++ Architecture is designed to have multiple threads of instructions executing in parallel. Each of these threads is like a Virtual Machine, with its own Instruction Pointer, Control Registers and Physical Data Registers. Each thread runs independently from, and in parallel to, all other threads. The typical RISC++ “Core” has two IPs, two sets of CRs, two banks of Fast Integer Registers, and two banks of Scalar Registers. The Vector Registers and Vector Execution units are shared between all the cores and allocated and released as needed. The two threads run simultaneously, sharing the EUs on a cycle by cycle basis. 

RISC++ defines a “Core” as having multiple threads, each with its own Instruction Pointer, Control Registers and Data Registers. The Core shares the EUs between multiple threads. The number of threads per Core is a decision made by hardware designers. Because registers are saved continually, the time it takes to switch threads is greatly reduced. Also, even though there are many Virtual Registers, there are only as many Physical Registers as are needed to keep the EUs busy. This mean


Register Save Engine (RSE)
1.	Instruction Pointer (IP): Controls Instruction flow for unified Scalar and Vector processes.
2.	Base Pointer (BP): Defines the 
3.	Control Registers, 
4.	
5.	Scalar Data Registers and Type/Status Registers (TSRs). Each TSR is 8 bits long and defines the Data Type and Status of a corresponding Register. There are 64 Scalar TSRs, one for each 64-bit Scalar Register; and 64 Vector TSRs, one for each 128-bit Vector Register. There is also 256 Scalar TSRs for each of the 256 x 64-bit entries on the Stack. All these registers make up the Machine State.
When one execution thread is to be swapped out and a new one started, the entire set of registers needs to be saved and a new set needs to be loaded. To save time during thread switching, the Register Save Engine continually pre-saves modified registers. The registers are saved in fixed offsets from the Base Pointer (BP), which defines the Program Space for the current execution thread. A thread switch changes to a new BP which points to a new set of saved registers. After the thread switch, he RSE knows that the Machine State is invalid and causes saved registers to be reloaded as soon as there is an attempt to access them. The Register Save Area (RSA) is the first 4096 bytes of the Program Space as shown below:
Offset	Length	Register Type	Register Function
0000 	128	16 x 64  Bit Control Registers	Control Program Execution
0128 	256	256 x 8  Bit Stacked TSRs	Data Type and Status for Stacked Registers
0384	64	64  x 8  Bit Scalar  TSRs	Data Type and Status for Scalar Registers
0448	64	64  x 8  Bit Vector  TSRs	Data Type and Status for Vector Registers
0512	512	64 x 64  Bit Scalar  Registers	Used for computing Scalar operations
1024	1024	64 x 128 Bit Vector  Registers	Used for computing Vector operations
2048	2048	256 x 64 Bit Stacked Registers	Used with PUSH and POP Instructions
7.3.	TYPE/STATUS REGISTERS (TSR)
The TSRs are the foundation of the RISC++ Architecture. The instruction set, the pipeline execution stages, the Execution Units, the Register Save Engine, the Branches and Conditional Instructions, the way the industry standards are implemented, the way Out of Order Execution is implemented, and the support for Queued Operands, all center around the definition of the TSRs. 
TSRs are the Metadata which defines the contents of Data Registers. The first four bits in each TSR define the Data Type of the corresponding registers. This allows generic instructions in which the data type is not defined by the binary Operation Code (OP Code) but by the data types of the input registers. Just as in languages like C++, the data is declared with a data type (Integer, Floating point, etc.) but the instructions (ADD, SUBTRACT, etc.) apply to all data types. This facilitates “run time dynamic typing” or “operator overloading” in the C++ or language. See the Wikipedia article: Type System for more information.
The last four bits of the TSR indicate the Status of the instruction which produced the associated register. The status bits control instruction dispatching. They enable conditional instructions and conditional branches to be eliminated from the instruction stream or else sent to various reservation stations to await execution. The TSRs tell the reservation stations when all the input data operands are available so that an instruction can be dispatched using Out of Order Execution. They also inform the dispatch unit if an error has occurred and if an interrupt should be signaled. Interrupt conditions are detected when a register is consumed rather than when it is produced. RISC++ interrupts are “imprecise” and are detected after the instru.
7.4.	 SCALAR AND VECTOR TYPE AND STATUS CODE DEFINITIONS
The following table defines the Data Types for 64 bits and 128 bits, Scalar and Vector Registers:
Type 	CODE	64-bit Scalar Data Types	CODE	128-bit Scalar and Vector Data Types
0000	UR64	Uninitialized Register	UR128	Uninitialized Register
0001	T164	64 bit Generic Type 1	T1128	128 bit Generic Type 1
0010	T264	64 bit Generic Type 2	T2128	128 bit Generic Type 2 
0011	T364	64 bit Generic Type 3	T3128	128 bit Generic Type 3 
0100	BF16	16 Bit Binary  Floating Point	VBF16	8 x 16  Bit Binary  Floating Point Vector
0101	BF32	32 Bit Binary  Floating Point	VBF32	4 x 32  Bit Binary  Floating Point Vector
0110	BF64	64 Bit Binary  Floating Point	VBF64	2 x 64  Bit Binary  Floating Point Vector
0111	DF64	64 Bit Decimal Floating Point	VDF64	2 x 64  Bit Decimal Floating Point Vector
1000	IS08	8  Bit Integer Signed	VIS08	16 x 8  Bit Integer Signed Vector
1001	IS16	16 Bit Integer Signed	VIS16	8  x 16 Bit Integer Signed Vector
1010	IS32	32 Bit Integer Signed	VIS32	4  x 32 Bit Integer Signed Vector
1011	IS64	64 Bit Integer Signed	VIS64	2  x 64 Bit Integer Signed Vector
1100	IU08	8  Bit Integer Unsigned	VIU08	16 x 8  Bit Integer Unsigned Vector
1101	IU16	16 Bit Integer Unsigned	VIU16	8  x 16 Bit Integer Unsigned Vector
1110	IU32	32 Bit Integer Unsigned	VIU32	4  x 32 Bit Integer Unsigned Vector
1111	IU64	64 Bit Integer Unsigned	VIU64	2  x 64 Bit Integer Unsigned Vector
Status Bit Definitions for Scalar Registers
The status bits are different depending on the data type field. Scalar status codes are not the same as Vector status codes, and Integer Status codes are not the same as Floating-Point Status codes. The type codes 0000 (Uninitialized Register); 0001; 0010; and 0011; all have unique status bits which are different than the status bits of the other Scalar and Vector data types.
Integer and Floating-Point Scalar Status Codes: 
The Scalar Status Codes are different for Integer or Floating-Point data and describe the contents of the scalar registers. These codes are based on the IEEE 754-2008 standard and will be explained in more detail later.
•	The Integer data types are 8, 16, 32, 64 and 128 bits Signed and Unsigned. 
•	The Binary Floating-Point data types are 16, 32, 64 and 128 bits. 
•	The Decimal Floating-Point data types are 64 and 128 bits. 
RISC++ defines a “Software Assist” status code which facilitates software emulation of any operations or data types not supported by a specific hardware implementation.
CODE	Integer	Floating Point
0000	Positive, Not Carry, Zero	Positive, Zero
0001	Positive, Not Carry, Not Zero	Positive, Not Zero
0010	Positive, Carry,     Zero	Positive, Sub-Normal
0011	Positive, Carry      Not Zero	Positive, Infinity
0100	Negative, Not Carry, Zero	Negative, Zero
0101	Negative, Not Carry, Not Zero	Negative, Not Zero
0110	Negative, Carry,     Zero	Negative, Sub-Normal
0111	Negative, Carry      Not Zero	Negative, Infinity
1000	Overflow	Overflow
1001	Underflow	Underflow
1010	Invalid Operation	Invalid Operation
1011	Divide by zero	Divide by Zero
1100		Inexact Result
1101		
1110	Data Type Error	Data Type Error
1111	Software Assist	Software Assist
7.5.	SCALAR LOAD AND STORE INSTRUCTIONS
The Scalar Load instructions specify the type of the data as it is in memory. As the data is moved from memory to a register (Load Instruction) it is reformatted to fit the internal 64-bit format. Then the TSR is set to the original memory data type. This allows data types to be intermixed during instruction execution. The rules for intermixing data types will be explained later. When the data is to be moved from a register to memory (Store Instruction) it is converted from the internal format to the format in memory using the TSR type code. The size of the data in memory is the number of bits specified in the TSR type code. The reformatting is as follows:
Load Integer Signed   8, 16 and 32 bits: propagate the sign bit to 64 bits.
Load Integer Unsigned 8, 16 and 32 bits: propagate zero to 64 bits.
Load Binary Float 16, 32 bits: Convert to Binary Float 64 bits.
Load Binary or Decimal Float 64 bits: Full 64 bits moved with no data conversion.
Store Integer Signed/Unsigned 8, 16, 32 bits: only low order bits are stored.
Store Binary Float 16, 32 bits: Data converted to 16 or 32 bits format before Store.
Store Binary or Decimal Float 64 bits: Full 64 bits stored unchanged.
The format of Load and Store Scalar instructions is as follows:
8 Bits	6 Bits	2 bits	16 Bits
OP Code	Source/Target Register (RS/RT)	RA	Immediate Data
RS is the Source Register for Store Instructions. RT is the Target Register for Load Instructions. RA specifies one of four Data Address Registers which are Control Registers. The 16-bit Immediate Data field is added to RA to form the address in memory for the Load or Store. The data type of scalar load instructions is specified in the OP code. The data type of store instructions is from the TSR of the register being stored.
Scalar Load and Store Instruction Definitions
OP Code	Mnemonic	Instruction
20 (32)	ST64	Store 64-bit Scalar Register  (Type in TSR defines type in memory)
21 (33)	LDCR	Load Control Register         (Type: 0001, Status to CR #)
22 (34)	LDIP	Load Instruction Pointer      (Type: 0010, Status TBD)
23 (35)	LDDP	Load Data Pointer             (Type: 0011, Status TBD)
24 (36)	LDBF16	Load 16 bit Binary  Float     (Type: 0100, Status: Register contents)
25 (37)	LDBF32	Load 32 bit Binary  Float     (Type: 0101, Status: Register contents) 
26 (38)	LDBF64	Load 64 bit Binary  Float     (Type: 0110, Status: Register contents) 
27 (39)	LDDF64	Load 64 bit Decimal Float     (Type: 0111, Status: Register contents) 
28 (40)	LDIS08	Load 08 bit Integer Signed    (Type: 1000, Status: Register contents)
29 (41)	LDIS16	Load 16 bit Integer Signed    (Type: 1001, Status: Register contents) 
2A (42)	LDIS32	Load 32 bit Integer Signed    (Type: 1010, Status: Register contents) 
2B (43)	LDIS64	Load 64 bit Integer Signed    (Type: 1011, Status: Register contents) 
2C (44)	LDIU08	Load 08 bit Integer Unsigned  (Type: 1100, Status: Register contents) 
2D (45)	LDIU16	Load 16 bit Integer Unsigned  (Type: 1101, Status: Register contents) 
2E (46)	LDIU32	Load 32 bit Integer Unsigned  (Type: 1110, Status: Register contents) 
2F (47)	LDIU64	Load 64 bit Integer Unsigned  (Type: 1111, Status: Register contents) 
30 (48)	ST128	Store 128 bit Scalar Register (Type in TSR defines type in memory)
31 (49)	LDIS128	Load 128 bit Integer Signed   (Type: 0001, Status: Register contents) 
32 (50)	LDBF128	Load 128 bit Binary  Float    (Type: 0010, Status: Register contents)
33 (51)	LDDF128	Load 128 bit Decimal Float    (Type: 0011, Status: Register contents) 
7.6.	LOAD AND STORE USING POINTER INSTRUCTIONS
Scalars and Vectors can be moved between memory and the registers using Pointer instructions. The vector in memory may be very long with thousands of data elements which all have the same data type. 128 bit Vector Registers hold a segment of the memory based vector. RISC++ defines three sizes of the vector segments: 128 bits, 256 bits and 512 bits. Pointer instructions can also be used to move a single element of a vector into a 64 bit or 128 bit scalar register.
There are three steps to using pointer instructions to move data between memory and the registers. First, the address of the pointer must be initialized in the pointer using the Set Pointer Address (SPA) instruction:
8 Bits	6 Bits	2 bits	16 Bits
OP Code	Pointer Register RP	RA	Immediate Data
The address of the data in memory is calculated by adding the Immediate Data to the Address Register (AR). Then the calculated address is put into the Pointer Register. The SPA instruction sets the 16 control bits of the Pointer Register are set to zero, which means it is an untyped pointer. 
The second step is to use the Set Bits Immediate (SBI) instruction to set control bits in the pointer. The format of the SBI instruction is:
8 bits	6 bits	2 bits	16 bits
Op Code	Target Register RT	F#	Immediate Control Bits
This instruction uses F# = 00 to set the upper 16 control bits in RT. This instruction will be defined in more detail. The 16 control bits are defined below and will be explained later:
Bits   0-3: Data Type 
            0000: Un-typed Pointer, Bits 4-15 to be defined. 
            0001 to 1111: 64 or 128-bit Data Type as defined earlier. 
Bits   4-5: Data Length: 
            00 = 64 bit Scalar 
            01 = 128 bit Scalar or Vector
            10 = 256 bit Vector
            11 = 512 bit Vector
Bits   6-7: Field Number for Vector or Scalar Control Register
Bit      8: 1 = Auto Update Pointer Address
Bit      9: 1 = Auto Update Register ID 
Bits 10-15: Register ID
The third step is to Load or Store data using the typed Pointer Register (PR). Some instructions use an Index Register (IR) which is added to the Data Address in the Pointer Register. The Data Type and Length is defined by the control bits of the Pointer Register. If bit 1 in the control field of the PR is 0, the data to be loaded or stored is scalar. The IR will select a single data element of the vector. If bit 1 is 1, the data to be loaded or stored is a vector segment of length 128, 256 or 512 bits. The IR will select the first data element in the vector segment in memory. The number of elements (#e) in a vector segment depends on the number of bits in the data type and the length of the vector segment. The table below shows the number of elements in different vectors:
Data types: (see mnemonics for
Load instructions above) 	Data Type 
Length	Vector Length 128 bits	Vector Length 256 bits	Vector Length
512 bits
IS08, IU08	8  bits	16 elements	32 elements	64 elements
IS16, IU16, BF16	16 bits	8  elements	16 elements	32 elements
IS32, IU32, BF32	32 bits	4  elements	8  elements 	16 elements
IS64, IU64, BF64, DF64	64 bits	2  elements	4  elements	8  elements
The Load and Store with Pointer and Index instructions have the following format:
8 bits	6 bits	6 bits	6 bits	6 bits
Op Code	Target Register RT	Pointer Register RP	Index Register RI	Condition Register RC
The instructions that use a pointer and index registers are:
LDPI:  Load Pointer with Index:  Used with both Scalar and Vector Target Registers
STPI:  Store Pointer with Index: Used with both Scalar and Vector Source Registers 
When the LDVPI is executed, the Index Register is multiplied by the number of elements in the vector segment and then added to the data address in RP. 
To illustrate how the Index Register is used, consider the following C++ code:
for (i = 0; i < 256; i++) VT[i] = VA[i] + VB[i];  
The RISC++ assembler code would be:
     LDI R3,0                 Load immediate data 0 into R3
     LDI R4,256               Load immediate data 256 into R4
Loop LPA R5,VA                Load pointer address to start of Vector A
     LPA R6,VB                Load pointer address to start of Vector B
     LPA R7,VT                Load Pointer address to start of Vector T
     LVP R8,R5,R3,IS08,V512   Load Integer signed 8 bit, 512-bit vector segment into VR8  to VR11
     LVP R12,R5,R3,IS08,V512  Load Integer signed 8 bit, 512-bit vector segment into VR12 to VR15
     LVP R16,R5,R3,IS08,V512  Load Integer signed 8 bit, 512-bit vector segment into VR16 to VR19
     INC R2,R3,R4,IS08,V512   Increment R3 (index) by  compare to R4

7.7.	UNINITIALIZED DATA AND CONTROL REGISTER STATUS CODES
The Un-typed Registers’ status bits are used for registers which have not received a data type. Busy conditions tell the hardware the temporary status of registers which are in the process of being updated. The three busy conditions apply to registers whose instructions that are in Reservation Stations waiting to be dispatched. 
The Busy Normal Operation status puts the instruction in a reservation station where it waits for input registers to become available. Other instructions which already have their input data are dispatched, sometimes out of the program order. When there are no more instructions to dispatch from the current thread, the hardware starts dispatching instructions from a parallel thread using Simultaneous Multithreading. 
The Busy Special Operation status may take the instruction more time to finish so the probability of switching to a parallel thread is greater. If the busy condition is due to a Cache Miss, the hardware will most likely switch to a parallel thread. 
Un-typed Registers may also have an error status which will generate an interrupt such as the b’1111’ (memory error) status code.  Other conditions that cause interrupts will also be defined.
There are 16 Control Registers that control the operation of the hardware. If a Control Register is copied to one of the 64-bit Scalar Registers, the type code of 0001 is set and the Status field is set to the number of the Control Register. The same is true if a Control Register is pushed to the Stack. Any attempt to write a Control Register back to the wrong register number will result in a program error interrupt.
CODE	Un-typed Register	Control Register
0000	Register Not Initialized	Base Pointer
0001	Busy Normal Operation	Data Address Register 1
0010	Busy Special Operation	Data Address Register 2
0011	Busy Cache Miss	Data Address Register 3
0100	Register Archived	Current Instruction Pointer
0101		Instruction Address Register 1
0110		Instruction Address Register 2
0111		Instruction Address Register 3
1000		
1001		
1010		
1011		
1100		
1101		Scalar Control/Status Register
1110		Vector Control/Status Register
1111	Memory Error	Stack/Queue Control Register
7.8.	STATUS CODES FOR VECTOR REGISTERS
As with the Scalar TSRs, the first four bits of the TSR define the data type of the associated register and the last four bits define the status. The first two status bits indicate the data length of the vector. The last two bits indicate which of four 16 bit fields in the Vector Control/Status Register applies to this register.
Bits 
1-2	Vector Length	Bits
3-4	Control/Status Field #
00	128 bit Vector Segment	00	Default Control/Status – Bits  0 - 15
01	128 bits – 16 bytes	01	Control/Status Field 1 – Bits 16 - 31
10	256 bits – 32 bytes	10	Control/Status Field 2 – Bits 32 - 47
11	512 bits – 64 bytes	11	Control/Status Field 3 – Bits 48 - 63
7.9.	VECTOR DATA LENGTHS AND TYPES
Vectors can be 128, 256 or 512 bits long. Vectors hold a minimum of 2 and a maximum of 64 data elements with element lengths of 8 bits to 64 bits. The data elements are held in 2 to 64 slots of the vector. The 128 bit Scalar data types have the same status codes as the Integer and Floating point scalars as defined above. The Status codes are not interpreted as Vector Length and Control/Status Field # as in the case of the Vector Types. RISC++ does not define 256 or 512 bit long Scalars. However, the carry bit in the 128 bit Integer Signed Scalar can be used to construct very long integers. These can be used as long Cipher Keys.
Type	128-bit Vector/Scalar	256-bit Vector	512-bit Vector
0000	Uninitialized Register	Uninitialized Register	Uninitialized Register
0001	128 bit Integer Signed Scalar	Undefined	Undefined
0010	128-bit Binary Float  Scalar	Undefined	Undefined
0011	128-bit Decimal Float Scalar	Undefined	Undefined
0100	8  x 16 bit Binary  Float	16 x 16 bit Binary  Float	32 x 16 bit Binary  Float
0101	4  x 32-bit Binary  Float	8  x 32-bit Binary  Float	16 x 32-bit Binary  Float
0110	2  x 64-bit Binary  Float	4  x 64-bit Binary  Float	8  x 64-bit Binary  Float
0111	2  x 64-bit Decimal Float	4  x 64-bit Decimal Float	8  x 64-bit Decimal Float
1000	16 x 8  bit Integer Signed	32 x  8 bit Integer Signed	64 x  8 bit Integer Signed
1001	8  x 16 bit Integer Signed	16 x 16 bit Integer Signed	32 x 16 bit Integer Signed
1010	4  x 32 bit Integer Signed	8  x 32 bit Integer Signed	16 x 32 bit Integer Signed
1011	2  x 64 bit Integer Unsigned	4  x 64 bit Integer Unsigned	8  x 64 bit Integer Unsigned
1100	16 x 8  bit Integer Unsigned	32 x  8 bit Integer Unsigned	64 x  8 bit Integer Unsigned
1101	8  x 16 bit Integer Unsigned	16 x 16 bit Integer Unsigned	32 x 16 bit Integer Unsigned
1110	4  x 32 bit Integer Unsigned	8  x 32 bit Integer Unsigned	16 x 32 bit Integer Unsigned
1111	2  x 64 bit Integer Unsigned	4  x 64 bit Integer Unsigned	8 x  64 bit Integer Unsigned
Setting Data Type and Status in 
Setting Status Data Length Codes in Vector TSRs
The data type and data length fields are set when the Vector is first loaded from memory. When a Vector Register is loaded from memory the Vector Data Type and Vector Length are specified in either the instruction OP Code or as fields in the Data Pointer. All the vectors use the same set of 64 x 128-bit registers. The 128-bit Vectors are held in one register with a length code of b01. 
The 256-bit Vectors are held in two registers which must be an even/odd pair. The even register will have a length code of b10 and the odd register will have a code of b00. 
The 512-bit Vectors are held in four registers which must be on a four register boundary. The first register in the group will have a length code of b11 and the next three will have a code of b00. 
There are a maximum of 32 x 256-bit vectors and 16 x 512-bit vectors. Vectors of different lengths can be intermixed in a program as long as the boundary rules are followed. Any Vector Instruction that attempts to access a register with a vector length code of b00 will set an Invalid Instruction status code.
These rules about register boundaries greatly simplify the design of instruction decode hardware. They also ensure that there are no data dependencies between Vectors of various lengths. The register boundary is useful during compiler design and testing. Boundary checking can be shut off to speed up the instruction pipeline when compiler generated code has been fully tested. Some hardware designers may choose to ignore boundary checking altogether. In this case, the low order bits on Register identifiers for 256 and 512-bit vectors will be set to zero, forcing proper boundaries.
The type and length of input registers determine the operation of the instruction. Most of the time, input (Source) vectors should both have the same type and length. The output (Target) vector will be assigned the same type and length as the input registers. The vector instruction operates on each element in the input vectors and produces an output vector which contains the results of the operation on an element by element basis. 
Setting Control/Status Field in Vector TSRs
When a Vector Register is loaded from memory, the Control/Status Field specifier is set to b’00’. This means that such things as Rounding Control, Interrupt Control and the various Status bits of the Vector, use bits 0-15 of the Vector Control / Status Register. 
Unlike Scalar Registers which have only one status, Vector Registers have different status conditions for various elements of the vector. For example, a 128-bit vector with 4 x 32-bit Binary Floating Point elements may have values of Normal, Infinity and NAN in one register. Each of these values sets a different status bit. The status bits are “sticky” which means once they are set, they remain set until reset. In this way, status conditions can accumulate over many instructions. A common use of the Control/Status bits is to set up conditions that will generate an interrupt. The “Try/Catch” operations on some programming languages would use these bits. The Vector TSR for input registers is propagated to new target registers as they are written. 
Instruction for Setting Control/Status (CS) Fields
The SETVCS instruction used to set the CS bits in the VCR is illustrated below:
8 Bits	6 bits	2 bits	16 Bits
OP Code	Target TSR	Field # 	Immediate Data
The SETVCS instruction sets one of 4 x 16 bit CS fields in the Vector Control Register (VCR) to the value of the Immediate Data in the instruction. The other fields of the VCR remain unchanged. The Field Number (F#) bits of the Target TSR set to the value of the F# in the instruction. When a future instruction is executed, the Source TSR specifies a particular F# which controls how the instruction operates. If two input registers have different F# then the larger number is used and propagated to the target TSR. In this way the programmer can set up a thread of instructions will all use the same CS bits. 
This includes instructions that are executed Out of Order. Status bits remain set until they are examined and reset. The status is accumulated across many instructions and elements in the vectors. The Test Vector CS instruction: (TVCS CRT, F#, I16) uses a 16 bit mask to select bits to be tested in the CS field specified by the F#. If any of those bits are set, the Condition Register (CR) is set to “True”. Ex: If the tested status bit is NAN, this will indicate that a NAN value has been set in at least one slot in at least one vector. Further testing can find the exact elements with a value of NAN.





The format of the Conditional Vector Instructions is shown below:
The Condition Register is a 64 bit scalar of type 64 bit Unsigned Integer. Each bit in the CR represents a byte in the input vectors. Only those bytes in the input vectors whose corresponding bit in the CR is set to one, are operated on by the instruction. Those bytes whose corresponding bits in the CR are zero, are set to zero in the target vector. A 512 bit vector is 64 bytes long uses all 64 bits in the CR. The shorter vectors only use the number of bits corresponding to the length of the vector. We will examine the use of the CR and the instructions which set its bits in more detail later in the document.
Suppose we want to ADD two input vectors of length 128 bits and type 8 x 16 bit Integer Signed:
•	Vector ADD: VADD VT, VA, VB, CR:  IF CR[n] != 0 THEN VT[N] = VA[N] + VB[N]
•	Where CR[n] is the bit number in CR and VT[N] is the slot or element in the vector
•	Since CR is R1 (all ones): The instruction is executed in every slot.
•	VA = |  1 |  2 |  3 |  4 |  5 |  6 |  7 |  8 | 
•	        +    +    +    +    +    +    +    +
•	VB = | -1 |  5 | -2 |  4 |  3 | -4 |  7 | 12 |
•	        =    =    =    =    =    =    =    =
•	VT = |  0 |  7 |  1 |  8 |  8 |  2 | 14 | 20 |
7.10.	RANDOM ACCESS OPERAND INSTRUCTIONS
Many RISC++ instructions are 32 bits in length and have an 8 bit op code and four 6 bit register specifications.

8 bits	6 bits	6 bits	6 bits	6 bits
OP CODE	Target Register RT	Source Register RX	Source Register RY	Source Register RZ

This allows up to 64 x 64 bit Scalar Registers and 64 x 128 bit Vector Registers. Each Scalar and Vector register has an 8 bit TSR associated with it. Some instructions have one Target Register (RT) and three Source Registers (RX, RY and RZ). Examples:  
Multiply Add:             MADD  RT, RX, RY, RZ:   RT =  (RX * RY) + RZ
Multiply Subtract:        MSUB  RT, RX, RY, RZ:   RT =  (RX * RY) - RZ
Multiply Negate Add:      MNADD RT, RX, RY, RZ:   RT = -(RX * RY) + RZ
Multiply Negate Subtract: MNSUB RT, RX, RY, RZ:   RT = -(RX * RY) – RZ
Sum of 3:                 SUM3  RT, RX, RY, RZ:   RT =   RX + RY + RZ
Average of 3:             AVG3  RT, RX, RY, RZ:   RT =  (RX + RY + RZ) / 3
Shift Left Then OR        SLOR  RT, RX, RY, RZ:   RT =  (RX <<< RY) OR RZ                 
Conditional Scalar Instructions
Conditional Scalar Instructions have the following format:
8 bits	6 bits	6 bits	6 bits	6 bits
OP CODE	Target Register RT	Source Register RX	Source Register RY	Condition Register CR


The third source register is a Condition Register (CR). If the value of CR is zero, the condition is False and the instruction is skipped. If CR is not zero, the condition is True and the instruction is executed. Since the scalar TSRs have zero/not zero as status codes, only the eight bit TSR needs to be tested, instead of the whole register, to see if the condition is true or false. 
64 bit Scalar Registers 0 and 1 have special meanings. 
•	Register 0 (R0) always reads a value of all zeros: Writes to Register 0 are ignored. 
•	Register 1 (R1) always reads a value of all ones:  Writes to Register 1 are ignored.
The CR is usually set by Compare instructions which set RT to all zeros or all ones. Sometimes Bitwise Logical Instructions (AND, OR, XOR, NOT) also operate on RT to produce a True/False condition that will be used by subsequent Conditional Instructions. Consider the following C++ code:
       IF A < B AND C > D 
          THEN E = A - B;
          ELSE E = C + D;

      The RISC++ Assembler code would be: 
      LDIS32 R4,  A:           Load variable A into R4; Set TSR Data Type to 32 bit Integer Signed
      LDIS32 R5,  B:           Load variable B into R4; Set TSR Data Type to 32 bit Integer Signed
      LDIS32 R6,  C:           Load variable C into R4; Set TSR Data Type to 32 bit Integer Signed
      LDIS32 R7,  D:           Load variable D into R4; Set TSR Data Type to 32 bit Integer Signed
      CLT    R8,  R4, R5, R1:  IF R1 THEN R8 = R4 < R5; (CR is R1: instruction always executed)
      CGT    R9,  R6, R7, R1:  IF R1 THEN R9 = R6 > R7; 
      AND    R10, R8, R9, R1:  IF R1 THEN R10 = R8 AND R9: 
      NOT    R11, R10, R1:     IF R1 THEN R11 = NOT R10 (To be used in ELSE clause)
      SUB    R12, R4, R5, R10: IF R10 THEN R12 = R4 – R5: R10 is CR
      ADD    R12, R6, R7, R11: IF R11 THEN R12 = R6 + R7: R11 is CR
      ST     R12, E:           Store R12 in Variable E: Data Type is 32 Bit Integer Signed

Scalar Compare and Test instructions set the value of CR to all zeros or all ones. For example the Compare Equal (CEQ) instruction compares RA and RB and if they are equal, it sets the RT to all ones. If they are not equal it sets RT to all zeros. If a Conditional Instruction specifies CR as R1, the instruction will always be executed because R1 is always not zero. R0 and R1 are very useful in Bitwise Logical Instructions. 
Scalar Compare Instructions
The following instructions set RT to all ones if the condition is True and all zeros if False:
CEQ RT, RX, RY, CR:   IF CR != 0 THEN RT = RX == RY (Compare Equal)
CNE RT, RX, RY, CR:   IF CR != 0 THEN RT = RX != RY (Compare Not Equal)
CLT RT, RX, RY, CR:   IF CR != 0 THEN RT = RX <  RY (Compare Less Than)
CLE RT, RX, RY, CR:   IF CR != 0 THEN RT = RX <= RY (Compare Less Than or Equal)
CGT RT, RX, RY, CR:   IF CR != 0 THEN RT = RX >  RY (Compare Greater Than)
CGE RT, RX, RY, CR:   IF CR != 0 THEN RT = RX >= RY (Compare Greater Than or Equal)
ISNAN RT, RX, CR:     IF CR != 0 THEN RT = ISNAN(RX) (IF RX is Not a Number THEN RT = True)
ISINF RT, RX, CR:     IF CR != 0 THEN RT = ISINF(RX) (IF RX is Infinity     THEN RT = True)
ISPOS RT, RX, CR:     IF CR != 0 THEN RT = ISPOS(RX) (IF RX is Positive     THEN RT = True)
ISNEG RT, RX, CR:     IF CR != 0 THEN RT = ISNEG(RX) (IF RX is Negative     THEN RT = True)
ISZER RT, RX, CR:     IF CR != 0 THEN RT = ISZER(RX) (IF RX is Zero         THEN RT = True)
ISNZE RT, RX, CR:     IF CR != 0 THEN RT = ISNZE(RX) (IF RX is Not Zero     THEN RT = True)
Conditional Vector Instructions
The Vector Registers can be accessed as 64 x 128 bit vectors, 32 x 256 bit vectors or 16 x 512 bit vectors. Vector Compare instructions produce a 64 bit Condition Register (CR) where each bit corresponds to a byte in the vector. The CR data type is a 64 bit Scalar. The elements of the vector range from 8 bits (1 byte) to 64 bits (8 bytes) in length. If an element is 8 bits long, the Vector Compare instruction sets 1 bit in the CR. If it is 16 bits (2 bytes), it sets 2 bits in the CR, and so forth. 
Since the 512 bit vectors are 64 bytes long, all 64 bits are used in CR and RT. Since R1 always has all 64 bits set to one it can be used in both Vector and Scalar instructions to indicate that the instruction will always be executed. Ex: two 128 bit vectors which each contain 4 x 32 bit signed integers:
RC is R1 (all ones) so every element of the vectors are compared
Each element is 4 bytes long so the compare sets 4 bits in CR
Vector Compare Less than or Equal: VCLE RT, VA, VB, CR:
IF CR[n] != 0 THEN RT[N] = VA[N] <= VB[N]
VA = |   500 |  -400 |   30  |  1000 |
         <=      <=      <=    <=
VB = |   200 |  -300 |   30  |  4000 |
         =       =       =      =
     | False |  True |  True |  True |
RT = | b0000 | b1111 | b1111 | b1111 | 
	The final value of RT is 0FFF 0000 0000 0000(in Hexadecimal). 
Vector Compare Instructions
The following instructions set bits in RT to ones if the condition is True and zeros if False:
VCEQ RT, VA, VB, CR:  IF CR[n]!= 0 THEN RT[n] = VA[N] == VB[N] (Vector Compare Equal)
VCNE RT, VA, VB, CR:  IF CR[n]!= 0 THEN RT[n] = VA[N] != VB[N] (Compare Not Equal)
VCLT RT, VA, VB, CR:  IF CR[n]!= 0 THEN RT[n] = VA[N] <  VB[N] (Compare Less Than)
VCLE RT, VA, VB, CR:  IF CR[n]!= 0 THEN RT[n] = VA[N] <= VB[N] (Compare Less Than or Equal)
VCGT RT, VA, VB, CR:  IF CR[n]!= 0 THEN RT[n] = VA[N] >  VB[N] (Compare Greater Than)
VCGE RT, VA, VB, CR:  IF CR[n]!= 0 THEN RT[n] = VA[N] >= VB[N] (Compare Greater Than or Equal)
VISNAN RT, VA, CR:    IF CR[n]!= 0 THEN RT[n] = ISNAN(VA[N]) (RT[n] = True IF VA[N] is Not a Number)
VISINF RT, VA, CR:    IF CR[n]!= 0 THEN RT[n] = ISINF(VA[N]) (RT[n] = True IF VA[N] is Infinity)
VISPOS RT, VA, CR:    IF CR[n]!= 0 THEN RT[n] = ISPOS(VA[N]) (RT[n] = True IF VA[N] is Positive)
VISNEG RT, VA, CR:    IF CR[n]!= 0 THEN RT[n] = ISNEG(VA[N]) (RT[n] = True IF VA[N] is Negative)
VISZER RT, VA, CR:    IF CR[n]!= 0 THEN RT[n] = ISZER(VA[N]) (RT[n] = True IF VA[N] is Zero)
VISNZE RT, VA, CR:    IF CR[n]!= 0 THEN RT[n] = ISNZE(VA[N]) (RT[n] = True IF VA[N] is Not Zero)
7.11.	QUEUED ACCESS OPERAND INSTRUCTIONS
The Queue Control Register (QCR) configures a subset of the Scalar and/or Vector registers to be accessed as a circular queue. Special Queued instructions read input operands from the Queue Head (QH) and write the results to the Queue Tail (QT).
The 32 bit packet containing four Queued Operand (QOP) instructions is defined as follows:
8 bits	6 bits	6 bits	6 bits	6 bits
OP CODE	Queue OP 1	Queue OP 2	Queue OP 3	Queue OP 4

Each QOP reads 1, 2 or 3 input operands from the Queue Head (QH) and writes the single output operand to the Queue Tail (QT). Queued instructions are always unconditional. Queued instructions facilitate ILP by eliminating data dependencies. Since operands are always consumed in the order in which they were produced, the need for instructions to wait for input operands is greatly reduced. Binary code using queued instructions is very compact and efficient which decreases the amount of latency due to instruction cache misses.




Like the X86 and PowerPC, the RISC++ processor core is an OOOE design, but the ISA is specially designed to minimize data dependencies and thus maximize the amount of ILP inherent in the source code prior to decoding. This is done using queued operands which allows for single byte instructions. This results in a smaller instruction memory footprint than a typical RISC. The small memory footprint for the binary machine code allows more instructions to be squeezed into the instruction cache. Thus a larger number of instructions can be fetched and decoded out of high speed memory closer to the execution hardware. The number of Instruction Cache misses is reduced providing higher performance.
There are also eight bit instructions which read and write operands from the stack or queue. The Start Queued Instructions (SQI) OP code tells the decoder to switch to eight bit instruction decode mode. When the decoder in eight bit mode encounters an OP Code of x00 it advances to the next 32 bit boundary and switches back to 32 bit instruction mode. As with the 32 bit OP code format, each instruction is translated into a forty bit instruction which is placed into a 256 bit packet of six instructions.
The fact that there is a Type/Status Register associated with each of the 128 real registers, facilitates  ILP by eliminating the bottleneck that a single status register creates in typical serial stream architectures. The TSR also provides information about whether a register has a value of zero or not zero. This can be used by the instruction decoder to eliminate branches and conditional instructions when translating from 32 bit to 40 bit instructions.
The register renaming process will be explained in detail later, but for now suffice it to say that the registers on the queue, stack and random access array are renamed in to 7 bit values which define one of 128 “real” registers.

 
8.				CHANGES IN VERSION 3.0
Version 1.0 of RISC++ was published on Ars Technica for review by experts in both hardware and software design. Many excellent comments were made and can be found in a forum called RISC++ an Instruction Set Architecture. These comments were incorporated into Version 2.0, but when I decided to add a dedicated Vector Processor, I decided to skip directly to version 3.0 before publishing again. Some of the major changes in Version 3.0 are:
8.1.		SEPARATE SCALAR AND VECTOR PROCESSORS
Version 1.0 defined a unified processor for scalar and vector instructions using a common set of registers that were all 128 bits long. Version 3.0 defines separate Scalar and Vector processors. The scalar processor is optimized for Instruction Level Parallelism (ILP); the vector processor is optimized for Data Level Parallelism (DLP). Each processor type has its own internal registers, execution units, dedicated paths to memory, and several instruction threads executing in parallel. The scalar processor accesses small data units randomly and has many branches in the instruction stream. The vector processor has fewer branches and depends on condition registers to select individual data items in a vector which will be used in a calculation.  Each vector instruction is applied to several parallel data items simultaneously using Single Instruction Multiple Data (SIMD). Each SIMD instruction can process from 1 to 64 bytes of parallel data for a maximum of 512 bits. 
For an overview SIMD architectures see: SIMD Architectures (Ars Technica). See also: Data-Level Parallelism in SIMD Architectures.  (pdf) The following table compares the RISC++ Scalar and Vector processors:
SCALAR PROCESSOR	VECTOR PROCESSOR
Instruction Level Parallelism	Data Level Parallelism
Out of Order Execution	In Order Execution
Single Instruction Single Data (SISD)			Single Instruction Multiple Data (SIMD)
12 	Scalar Data Types (64 bit): single registers
3  Scalar Data Types (128 bit): dual registers	13 Vector Data Types: Variable length 1 to 64 bytes.
1  Scalar Integer Type (64 bit signed)
Data Types specified by Type/Status Register (TSR)	Data Types specified by Instruction Operation Code
Random Memory Access: 64 bits per load/store		Streaming Memory Access: 512 bits per load/store
Condition Registers hold one condition	Condition Registers hold up to 64 condition bits
Conditional Instructions Execute if Condition is True	Conditional Instructions Execute if Vector Slot is True




